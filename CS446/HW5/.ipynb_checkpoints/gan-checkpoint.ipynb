{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/234 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done. Total 60000 data entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/234 [00:00<00:50,  4.65it/s]\u001b[A\n",
      "  1%|          | 2/234 [00:00<00:34,  6.67it/s]\u001b[A\n",
      "  1%|▏         | 3/234 [00:00<00:30,  7.64it/s]\u001b[A\n",
      "  2%|▏         | 4/234 [00:00<00:30,  7.55it/s]\u001b[A\n",
      "  2%|▏         | 5/234 [00:00<00:28,  8.07it/s]\u001b[A\n",
      "  3%|▎         | 6/234 [00:00<00:27,  8.39it/s]\u001b[A\n",
      "  3%|▎         | 7/234 [00:00<00:27,  8.15it/s]\u001b[A\n",
      "  3%|▎         | 8/234 [00:01<00:26,  8.45it/s]\u001b[A\n",
      "  4%|▍         | 9/234 [00:01<00:30,  7.46it/s]\u001b[A\n",
      "  4%|▍         | 10/234 [00:01<00:28,  7.75it/s]\u001b[A\n",
      "  5%|▍         | 11/234 [00:01<00:28,  7.74it/s]\u001b[A\n",
      "  5%|▌         | 12/234 [00:01<00:28,  7.72it/s]\u001b[A\n",
      "  6%|▌         | 13/234 [00:01<00:27,  7.89it/s]\u001b[A\n",
      "  6%|▌         | 14/234 [00:01<00:30,  7.25it/s]\u001b[A\n",
      "  6%|▋         | 15/234 [00:01<00:28,  7.72it/s]\u001b[A\n",
      "  7%|▋         | 16/234 [00:02<00:27,  8.05it/s]\u001b[A\n",
      "  7%|▋         | 17/234 [00:02<00:27,  8.01it/s]\u001b[A\n",
      "  8%|▊         | 18/234 [00:02<00:26,  8.09it/s]\u001b[A\n",
      "  8%|▊         | 19/234 [00:02<00:27,  7.93it/s]\u001b[A\n",
      "  9%|▊         | 20/234 [00:02<00:26,  7.94it/s]\u001b[A\n",
      "  9%|▉         | 21/234 [00:02<00:26,  8.09it/s]\u001b[A\n",
      " 10%|▉         | 23/234 [00:02<00:23,  8.92it/s]\u001b[A\n",
      " 10%|█         | 24/234 [00:03<00:23,  8.86it/s]\u001b[A\n",
      " 11%|█         | 25/234 [00:03<00:25,  8.13it/s]\u001b[A\n",
      " 11%|█         | 26/234 [00:03<00:24,  8.44it/s]\u001b[A\n",
      " 12%|█▏        | 27/234 [00:03<00:25,  8.20it/s]\u001b[A\n",
      " 12%|█▏        | 28/234 [00:03<00:25,  8.20it/s]\u001b[A\n",
      " 12%|█▏        | 29/234 [00:03<00:25,  8.03it/s]\u001b[A\n",
      " 13%|█▎        | 30/234 [00:03<00:25,  8.00it/s]\u001b[A\n",
      " 13%|█▎        | 31/234 [00:03<00:26,  7.61it/s]\u001b[A\n",
      " 14%|█▎        | 32/234 [00:04<00:25,  7.86it/s]\u001b[A\n",
      " 14%|█▍        | 33/234 [00:04<00:27,  7.42it/s]\u001b[A\n",
      " 15%|█▍        | 34/234 [00:04<00:25,  7.93it/s]\u001b[A\n",
      " 15%|█▍        | 35/234 [00:04<00:24,  8.14it/s]\u001b[A\n",
      " 15%|█▌        | 36/234 [00:04<00:24,  8.24it/s]\u001b[A\n",
      " 16%|█▌        | 37/234 [00:04<00:22,  8.61it/s]\u001b[A\n",
      " 16%|█▌        | 38/234 [00:04<00:22,  8.52it/s]\u001b[A\n",
      " 17%|█▋        | 39/234 [00:04<00:23,  8.22it/s]\u001b[A\n",
      " 18%|█▊        | 41/234 [00:05<00:22,  8.60it/s]\u001b[A\n",
      " 18%|█▊        | 42/234 [00:05<00:23,  8.28it/s]\u001b[A\n",
      " 18%|█▊        | 43/234 [00:05<00:23,  8.15it/s]\u001b[A\n",
      " 19%|█▉        | 44/234 [00:05<00:23,  8.03it/s]\u001b[A\n",
      " 19%|█▉        | 45/234 [00:05<00:22,  8.37it/s]\u001b[A\n",
      " 20%|█▉        | 46/234 [00:05<00:21,  8.76it/s]\u001b[A\n",
      " 20%|██        | 47/234 [00:05<00:22,  8.23it/s]\u001b[A\n",
      " 21%|██        | 48/234 [00:05<00:22,  8.16it/s]\u001b[A\n",
      " 21%|██        | 49/234 [00:06<00:23,  7.96it/s]\u001b[A\n",
      " 21%|██▏       | 50/234 [00:06<00:22,  8.20it/s]\u001b[A\n",
      " 22%|██▏       | 52/234 [00:06<00:19,  9.28it/s]\u001b[A\n",
      " 23%|██▎       | 53/234 [00:06<00:19,  9.33it/s]\u001b[A\n",
      " 23%|██▎       | 54/234 [00:06<00:19,  9.15it/s]\u001b[A\n",
      " 24%|██▎       | 55/234 [00:06<00:20,  8.68it/s]\u001b[A\n",
      " 24%|██▍       | 56/234 [00:06<00:20,  8.81it/s]\u001b[A\n",
      " 24%|██▍       | 57/234 [00:06<00:19,  9.03it/s]\u001b[A\n",
      " 25%|██▍       | 58/234 [00:07<00:19,  9.15it/s]\u001b[A\n",
      " 25%|██▌       | 59/234 [00:07<00:19,  9.04it/s]\u001b[A\n",
      " 26%|██▌       | 60/234 [00:07<00:19,  8.87it/s]\u001b[A\n",
      " 26%|██▌       | 61/234 [00:07<00:19,  8.68it/s]\u001b[A\n",
      " 26%|██▋       | 62/234 [00:07<00:19,  8.76it/s]\u001b[A\n",
      " 27%|██▋       | 63/234 [00:07<00:20,  8.14it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-374ced5c25ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-374ced5c25ca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iter_d, iter_g, n_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loss_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                     \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m                     \u001b[0mdopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mdopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from hw5_utils import BASE_URL, download, GANDataset\n",
    "\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        \n",
    "        # TODO: implement layers here\n",
    "        self.conv1 = nn.Conv2d(1,2,3,padding=1)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(2,4,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(4,8,3)\n",
    "        self.fc = nn.Linear(5*5*8,1)\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "        nn.init.zeros_(self.conv3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: complete forward function\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        #x = torch.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNet(nn.Module):\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "        # TODO: implement layers here\n",
    "        self.fc1 = nn.Linear(zdim,1568)\n",
    "        #Relu\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        self.upsample1 = nn.Upsample(scale_factor =2)\n",
    "        self.conv1 = nn.Conv2d(32,16,3,padding=1)\n",
    "        ##Relu\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        self.upsample2 = nn.Upsample(scale_factor = 2)\n",
    "        self.conv2 = nn.Conv2d(16,8,3,padding = 1)\n",
    "        self.relu3 = nn.LeakyReLU(0.2)\n",
    "        self.conv3 = nn.Conv2d(8,1,3,padding = 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "        nn.init.zeros_(self.conv3.bias)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            z: latent variables used to generate images.\n",
    "        \"\"\"\n",
    "        # TODO: complete forward function\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        #z = F.leaky_relu(z,0.2)\n",
    "        z = z.view(-1,32,7,7)\n",
    "        z = self.upsample1(z)\n",
    "        #z = F.leaky_relu(self.conv1(z),0.2)\n",
    "        z = self.conv1(z)\n",
    "        z = self.relu2(z)\n",
    "        #z = self.relu2(self.conv1(z),0.2)\n",
    "        z = self.upsample2(z)\n",
    "        #z = F.leaky_relu(self.conv2(z),0.2)\n",
    "        z = self.conv2(z)\n",
    "        z = self.relu3(z)\n",
    "        z = self.conv3(z)\n",
    "        z = self.sigmoid(z)\n",
    "        #z = F.sigmoid(self.conv3(z))\n",
    "        #z = self.sigmoid(self.conv3(z))\n",
    "        return z\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, zdim=64):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(2)\n",
    "        self._dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self._zdim = zdim\n",
    "        self.disc = DNet().to(self._dev)\n",
    "        self.gen = GNet(self._zdim).to(self._dev)\n",
    "\n",
    "    def _get_loss_d(self, batch_size, batch_data, z):\n",
    "        \"\"\"This function computes loss for discriminator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size: #data per batch.\n",
    "            batch_data: data from dataset.\n",
    "            z: random latent variable.\n",
    "        \"\"\"\n",
    "        # TODO: implement discriminator's loss function\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss_real = criterion(self.disc(batch_data),torch.ones(batch_size,1))\n",
    "        loss_fake = criterion(self.disc(self.gen(z)),torch.zeros(batch_size,1))\n",
    "        #loss_real = criterion(self.disc(batch_data),torch.ones(batch_size,1),device = self._device)\n",
    "        #loss_fake = criterion(self.disc(self.gen(z)),torch.ones(batch_size,1),device = self._device)\n",
    "        loss_d = (loss_real + loss_fake)/2\n",
    "        return loss_d\n",
    "\n",
    "    def _get_loss_g(self, batch_size, z):\n",
    "        \"\"\"This function computes loss for generator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size: #data per batch.\n",
    "            z: random latent variable.\n",
    "        \"\"\"\n",
    "        # TODO: implement generator's loss function\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss_g = criterion(self.disc(self.gen(z)),torch.ones(batch_size,1))\n",
    "        return loss_g\n",
    "\n",
    "    def train(self, iter_d=1, iter_g=1, n_epochs=100, batch_size=256, lr=0.0002):\n",
    "\n",
    "        # first download\n",
    "        f_name = \"train-images-idx3-ubyte.gz\"\n",
    "        download(BASE_URL + f_name, f_name)\n",
    "\n",
    "        print(\"Processing dataset ...\")\n",
    "        train_data = GANDataset(\n",
    "            f\"./data/{f_name}\",\n",
    "            self._dev,\n",
    "            transform=transforms.Compose([transforms.Normalize((0.0,), (255.0,))]),\n",
    "        )\n",
    "        print(f\"... done. Total {len(train_data)} data entries.\")\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        dopt = optim.Adam(self.disc.parameters(), lr=lr, weight_decay=0.0)\n",
    "        dopt.zero_grad()\n",
    "        gopt = optim.Adam(self.gen.parameters(), lr=lr, weight_decay=0.0)\n",
    "        gopt.zero_grad()\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            for batch_idx, data in tqdm(\n",
    "                enumerate(train_loader), total=len(train_loader)\n",
    "            ):\n",
    "\n",
    "                z = 2 * torch.rand(data.size()[0], self._zdim, device=self._dev) - 1\n",
    "\n",
    "                if batch_idx == 0 and epoch == 0:\n",
    "                    plt.imshow(data[0, 0, :, :].detach().cpu().numpy())\n",
    "                    plt.savefig(\"goal.pdf\")\n",
    "\n",
    "                if batch_idx == 0 and epoch % 10 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        tmpimg = self.gen(z)[0:64, :, :, :].detach().cpu()\n",
    "                    save_image(\n",
    "                        tmpimg, \"test_{0}.png\".format(epoch), nrow=8, normalize=True\n",
    "                    )\n",
    "\n",
    "                dopt.zero_grad()\n",
    "                for k in range(iter_d):\n",
    "                    loss_d = self._get_loss_d(batch_size, data, z)\n",
    "                    loss_d.backward()\n",
    "                    dopt.step()\n",
    "                    dopt.zero_grad()\n",
    "\n",
    "                gopt.zero_grad()\n",
    "                for k in range(iter_g):\n",
    "                    loss_g = self._get_loss_g(batch_size, z)\n",
    "                    loss_g.backward()\n",
    "                    gopt.step()\n",
    "                    gopt.zero_grad()\n",
    "\n",
    "            print(f\"E: {epoch}; DLoss: {loss_d.item()}; GLoss: {loss_g.item()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gan = GAN()\n",
    "    gan.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (torch.ones(10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GNet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[11,4,2,1],[2,3,2,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten(\n",
       "  start_dim=tensor([[11,  4,  2,  1],\n",
       "          [ 2,  3,  2,  5]]), end_dim=-1\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  4,  2,  1,  2,  3,  2,  5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNet(nn.Module):\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "        # TODO: implement layers here\n",
    "        self.fc1 = nn.Linear(zdim,1568)\n",
    "        #Relu\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        self.upsample1 = nn.Upsample(scale_factor =2)\n",
    "        self.conv1 = nn.Conv2d(32,16,3,padding=1)\n",
    "        ##Relu\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        self.upsample2 = nn.Upsample(scale_factor = 2)\n",
    "        self.conv2 = nn.Conv2d(16,8,3,padding = 1)\n",
    "        self.relu3 = nn.LeakyReLU(0.2)\n",
    "        self.conv3 = nn.Conv2d(8,1,3,padding = 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "        nn.init.zeros_(self.conv3.bias)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            z: latent variables used to generate images.\n",
    "        \"\"\"\n",
    "        # TODO: complete forward function\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        #z = F.leaky_relu(z,0.2)\n",
    "        z = z.view(-1,32,7,7)\n",
    "        z = self.upsample1(z)\n",
    "        #z = F.leaky_relu(self.conv1(z),0.2)\n",
    "        z = self.conv1(z)\n",
    "        z = self.relu2(z)\n",
    "        #z = self.relu2(self.conv1(z),0.2)\n",
    "        z = self.upsample2(z)\n",
    "        #z = F.leaky_relu(self.conv2(z),0.2)\n",
    "        z = self.conv2(z)\n",
    "        z = self.relu3(z)\n",
    "        z = self.conv3(z)\n",
    "        z = self.sigmoid(z)\n",
    "        #z = F.sigmoid(self.conv3(z))\n",
    "        #z = self.sigmoid(self.conv3(z))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNet(\n",
       "  (conv1): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = DNet()\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNet2(\n",
       "  (f): Sequential(\n",
       "    (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2 = DNet2()\n",
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 28, 28])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,1,28,28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4360],\n",
       "        [0.7328],\n",
       "        [0.5797],\n",
       "        [0.0066],\n",
       "        [0.4851]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = g.forward(x)\n",
    "t1.size()\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2797],\n",
       "        [ 4.0545],\n",
       "        [-0.0111],\n",
       "        [ 5.7228],\n",
       "        [ 2.4843]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = g2.forward(x)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNet2(nn.Module):\n",
    "\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            zdim: dimension for latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(GNet2, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "\n",
    "            nn.Linear(zdim, 1568, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.f2 = nn.Sequential(\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        #self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f1.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "                print(child,child.weight)\n",
    "                print(child,child.bias)\n",
    "\n",
    "        for child in list(self.f2.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            z: latent variables used to generate images.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        hidden = self.f1(z)\n",
    "\n",
    "        return self.f2(hidden.view(-1, 32, 7, 7))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNet2(nn.Module):\n",
    "\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DNet2, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=0, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8*5*5, 1, bias=True)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        return self.f(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
