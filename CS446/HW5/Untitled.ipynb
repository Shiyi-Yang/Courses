{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "import matplotlib.image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from hw5_utils import *\n",
    "\n",
    "# from scipy.stats import lognorm\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "\n",
    "# The \"encoder\" model q(z|x)\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dimension, hidden_units, data_dimension):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Input:\n",
    "        #   latent_dimension: the latent dimension of the encoder\n",
    "        #   hidden_units: the number of hidden units\n",
    "        \n",
    "        self.fc1 = nn.Linear(data_dimension, hidden_units)\n",
    "        self.fc2_mu = nn.Linear(hidden_units, latent_dimension)\n",
    "        self.fc2_sigma = nn.Linear(hidden_units, latent_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: x input image [batch_size x data_dimension]\n",
    "        # Output: parameters of a diagonal gaussian \n",
    "        #   mean : [batch_size x latent_dimension]\n",
    "        #   variance : [batch_size x latent_dimension]\n",
    "\n",
    "        hidden = torch.tanh(self.fc1(x))\n",
    "        mu = self.fc2_mu(hidden)\n",
    "        log_sigma_square = self.fc2_sigma(hidden)\n",
    "        sigma_square = torch.exp(log_sigma_square)  \n",
    "        return mu, sigma_square\n",
    "\n",
    "\n",
    "# \"decoder\" Model p(x|z)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dimension, hidden_units, data_dimension):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Input:\n",
    "        #   latent_dimension: the latent dimension of the encoder\n",
    "        #   hidden_units: the number of hidden units\n",
    "\n",
    "        # TODO: deine the parameters of the decoder\n",
    "        # fc1: a fully connected layer with 500 hidden units. \n",
    "        # fc2: a fully connected layer with 500 hidden units. \n",
    "        self.fc1 = nn.Linear(latent_dimension, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, data_dimension)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # input\n",
    "        #   z: latent codes sampled from the encoder [batch_size x latent_dimension]\n",
    "        # output \n",
    "        #   p: a tensor of the same size as the image indicating the probability of every pixel being 1 [batch_size x data_dimension]\n",
    "\n",
    "        # TODO: implement the decoder here. The decoder is a multi-layer perceptron with two hidden layers. \n",
    "        # The first layer is followed by a tanh non-linearity and the second layer by a sigmoid.\n",
    "        hidden = torch.tanh(self.fc1(z))\n",
    "        p = torch.sigmoid(self.fc2(hidden))\n",
    "        return p\n",
    "\n",
    "\n",
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "    #def __init__(self, args):\n",
    "        super(VAE, self).__init__()\n",
    "        #self.latent_dimension = args.latent_dimension\n",
    "        #self.hidden_units =  args.hidden_units\n",
    "        #self.data_dimension = args.data_dimension\n",
    "        #self.resume_training = args.resume_training\n",
    "        #self.batch_size = args.batch_size\n",
    "        #self.num_epoches = args.num_epoches\n",
    "        #self.e_path = args.e_path\n",
    "        #self.d_path = args.d_path\n",
    "        self.latent_dimension = 2\n",
    "        self.hidden_units =  500\n",
    "        self.data_dimension = 784\n",
    "        self.resume_training = False\n",
    "        self.batch_size = 100\n",
    "        self.num_epoches = 10\n",
    "        self.e_path = \"e_params.pkl\"\n",
    "        self.d_path = \"d_params.pkl\"\n",
    "\n",
    "\n",
    "        # load and pre-process the data\n",
    "        N_data, self.train_images, self.train_labels, test_images, test_labels = load_mnist()\n",
    "\n",
    "        # Instantiate the encoder and decoder models \n",
    "        self.encoder = Encoder(self.latent_dimension, self.hidden_units, self.data_dimension)\n",
    "        self.decoder = Decoder(self.latent_dimension, self.hidden_units, self.data_dimension)\n",
    "\n",
    "        # Load the trained model parameters\n",
    "        if self.resume_training:\n",
    "            self.encoder.load_state_dict(torch.load(self.e_path))\n",
    "            self.decoder.load_state_dict(torch.load(self.d_path))\n",
    "\n",
    "    # Sample from Diagonal Gaussian z~N(μ,σ^2 I) \n",
    "    @staticmethod\n",
    "    def sample_diagonal_gaussian(mu, sigma_square):\n",
    "        # Inputs:\n",
    "        #   mu: mean of the gaussian [batch_size x latent_dimension]\n",
    "        #   sigma_square: variance of the gaussian [batch_size x latent_dimension]\n",
    "        # Output:\n",
    "        #   sample: from a diagonal gaussian with mean mu and variance sigma_square [batch_size x latent_dimension]\n",
    "\n",
    "        # TODO: Implement the reparameterization trick and return the sample z [batch_size x latent_dimension]\n",
    "        sample = torch.normal(mean=mu, std=torch.sqrt(sigma_square))\n",
    "        return sample\n",
    "\n",
    "    # Sampler from Bernoulli\n",
    "    @staticmethod\n",
    "    def sample_Bernoulli(p):\n",
    "        # Input: \n",
    "        #   p: the probability of pixels labeled 1 [batch_size x data_dimension]\n",
    "        # Output:\n",
    "        #   x: pixels'labels [batch_size x data_dimension]\n",
    "\n",
    "        # TODO: Implement a sampler from a Bernoulli distribution\n",
    "        x = torch.bernoulli(p)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # Compute Log-pdf of z under Diagonal Gaussian N(z|μ,σ^2 I)\n",
    "    @staticmethod\n",
    "    def logpdf_diagonal_gaussian(z, mu, sigma_square):\n",
    "        # Input:\n",
    "        #   z: sample [batch_size x latent_dimension]\n",
    "        #   mu: mean of the gaussian distribution [batch_size x latent_dimension]\n",
    "        #   sigma_square: variance of the gaussian distribution [batch_size x latent_dimension]\n",
    "        # Output:\n",
    "        #    logprob: log-probability of a diagomnal gaussian [batch_size]\n",
    "        \n",
    "        # TODO: implement the logpdf of a gaussian with mean mu and variance sigma_square*I\n",
    "        logprob = (-1/2*torch.log(sigma_square*2*np.pi)-(((z-mu)**2)/(2*sigma_square))).sum(axis=1)\n",
    "        return logprob\n",
    "\n",
    "    # Compute log-pdf of x under Bernoulli \n",
    "    @staticmethod\n",
    "    def logpdf_bernoulli(x, p):\n",
    "        # Input:\n",
    "        #   x: data samples [batch_size x data_dimension]\n",
    "        #   p: the probability of the x being labeled 1 (p is the output of the decoder) [batch_size x data_dimension]\n",
    "        # Output:\n",
    "        #   logprob: log-probability of a diagonal gaussian [batch_size]\n",
    "\n",
    "        # TODO: implement the log likelihood of a bernoulli distribution p(x)\n",
    "        logprob = (torch.log((x==1)*p+(x!=1)*(1-p))).sum(axis=1)\n",
    "        return logprob\n",
    "    \n",
    "    # Sample z ~ q(z|x)\n",
    "    def sample_z(self, mu, sigma_square):\n",
    "        # input:\n",
    "        #   mu: mean of the gaussian [batch_size x latent_dimension]\n",
    "        #   sigma_square: variance of the gaussian [batch_size x latent_dimension]\n",
    "        # Output:\n",
    "        #   zs: samples from q(z|x) [batch_size x latent_dimension] \n",
    "        zs = self.sample_diagonal_gaussian(mu, sigma_square)\n",
    "        return zs \n",
    "\n",
    "\n",
    "    # Variational Objective\n",
    "    def elbo_loss(self, sampled_z, mu, sigma_square, x, p):\n",
    "        # Inputs\n",
    "        #   sampled_z: samples z from the encoder [batch_size x latent_dimension]\n",
    "        #   mu:\n",
    "        #   sigma_square: parameters of q(z|x) [batch_size x 1]\n",
    "        #   x: data samples [batch_size x data_dimension]\n",
    "        #   p: the probability of a pixel being labeled 1 [batch_size x data_dimension]\n",
    "        # Output\n",
    "        #   elbo: the ELBO loss (scalar)\n",
    "\n",
    "        # log_q(z|x) logprobability of z under approximate posterior N(μ,σ)\n",
    "        log_q = self.logpdf_diagonal_gaussian(sampled_z, mu, sigma_square)\n",
    "        # log_p_z(z) log probability of z under prior\n",
    "        z_mu = torch.FloatTensor([0]*self.latent_dimension)\n",
    "        z_sigma = torch.FloatTensor([1]*self.latent_dimension)\n",
    "        log_p_z = self.logpdf_diagonal_gaussian(sampled_z, z_mu, z_sigma)\n",
    "        # log_p(x|z) - conditional probability of data given latents.\n",
    "        log_p = self.logpdf_bernoulli(x, p)\n",
    "        \n",
    "        # TODO: implement the ELBO loss using log_q, log_p_z and log_p\n",
    "        elbo = (log_p+log_p_z-log_q).mean()\n",
    "        return elbo\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        # Set-up ADAM optimizer\n",
    "        params = list(self.encoder.parameters()) + list(self.decoder.parameters())\n",
    "        adam_optimizer = optim.Adam(params)\n",
    "\n",
    "        # Train for ~200 epochs \n",
    "        num_batches = int(np.ceil(len(self.train_images) / self.batch_size))\n",
    "        num_iters = self.num_epoches * num_batches\n",
    "        for i in range(num_iters):\n",
    "            x_minibatch = self.train_images[batch_indices(i, num_batches, self.batch_size),:]\n",
    "            adam_optimizer.zero_grad()\n",
    "\n",
    "            mu, sigma_square = self.encoder(x_minibatch)\n",
    "            zs = self.sample_z(mu, sigma_square)\n",
    "            p = self.decoder(zs)\n",
    "            elbo = self.elbo_loss(zs, mu, sigma_square, x_minibatch, p)\n",
    "            total_loss = -elbo\n",
    "            total_loss.backward()\n",
    "            adam_optimizer.step()\n",
    "\n",
    "            if i%100 == 0:\n",
    "                print(\"Epoch: \" + str(i//num_batches) + \", Iter: \" + str(i) + \", ELBO:\" + str(elbo.item()))\n",
    "\n",
    "        # Save Optimized Model Parameters\n",
    "        torch.save(self.encoder.state_dict(), self.e_path)\n",
    "        torch.save(self.decoder.state_dict(), self.d_path)\n",
    "\n",
    "\n",
    "    # Generate digits using the VAE\n",
    "    def visualize_data_space(self):\n",
    "        # TODO: Sample 10 z from prior \n",
    "        sample_size = 10\n",
    "        z_mu = torch.FloatTensor([[0]*self.latent_dimension for _ in range(sample_size)])\n",
    "        z_sigma = torch.FloatTensor([[1]*self.latent_dimension for _ in range(sample_size)])\n",
    "        zs = self.sample_diagonal_gaussian(z_mu, z_sigma)\n",
    "\n",
    "        # TODO: For each z, plot p(x|z)\n",
    "        ps = self.decoder(zs)\n",
    "        images_p = torch.tensor([array_to_image(p.detach()) for p in ps])\n",
    "\n",
    "        # TODO: Sample x from p(x|z) \n",
    "        xs = self.sample_Bernoulli(ps)\n",
    "        images_x =torch.tensor([array_to_image(x.detach()) for x in xs])\n",
    "\n",
    "        images = torch.cat((images_p, images_x))\n",
    "        result = concat_images(images, sample_size, 2)\n",
    "\n",
    "        # TODO: Save the generated figure and include it in your report\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(result, 'gray')\n",
    "        plt.savefig('concatenate.png')\n",
    "        plt.show()\n",
    "        print(result)\n",
    "        \n",
    "    # Produce a scatter plot in the latent space, where each point in the plot will be the mean vector \n",
    "    # for the distribution $q(z|x)$ given by the encoder. Further, we will colour each point in the plot \n",
    "    # by the class label for the input data. Each point in the plot is colored by the class label for \n",
    "    # the input data.\n",
    "    # The latent space should have learned to distinguish between elements from different classes, even though \n",
    "    # we never provided class labels to the model!\n",
    "    def visualize_latent_space(self):\n",
    "        \n",
    "        # TODO: Encode the training data self.train_images\n",
    "        mu, sigma_square = self.encoder(self.train_images)\n",
    "\n",
    "        # TODO: Take the mean vector of each encoding\n",
    "        colors = cm.rainbow(np.linspace(0, 1, 10))\n",
    "        labels = self.train_labels.argmax(axis=1)\n",
    "        colors = [colors[i] for i in labels]\n",
    "        # for i, m in enumerate(mu):\n",
    "        #     label = self.train_labels[i].argmax()\n",
    "        # TODO: Plot these mean vectors in the latent space with a scatter\n",
    "        # Colour each point depending on the class label \n",
    "            # plt.scatter(*np.array(m.detach()), label=label, color=colors[label])\n",
    "        plt.scatter(mu[:,0].detach(), mu[:,1].detach(), color=colors)\n",
    "        \n",
    "\n",
    "        # TODO: Save the generated figure and include it in your report\n",
    "        plt.legend()\n",
    "        plt.savefig('latent_space.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # Function which gives linear interpolation z_α between za and zb\n",
    "    @staticmethod\n",
    "    def interpolate_mu(mua, mub, alpha = 0.5):\n",
    "        return alpha*mua + (1-alpha)*mub\n",
    "\n",
    "\n",
    "    # A common technique to assess latent representations is to interpolate between two points.\n",
    "    # Here we will encode 3 pairs of data points with different classes.\n",
    "    # Then we will linearly interpolate between the mean vectors of their encodings. \n",
    "    # We will plot the generative distributions along the linear interpolation.\n",
    "    def visualize_inter_class_interpolation(self):\n",
    "        \n",
    "        # TODO: Sample 3 pairs of data with different classes\n",
    "        z_a = torch.ones(11, 2)\n",
    "        img = torch.zeros(3, 11, 28, 28)\n",
    "\n",
    "        labels = self.train_labels.argmax(axis=1)\n",
    "        for i in range(3):\n",
    "            x1 = self.train_images[labels==2*i][0]\n",
    "            x2 = self.train_images[labels==2*i+1][0]\n",
    "        # TODO: Encode the data in each pair, and take the mean vectors\n",
    "            mu1, sigma_square1 = self.encoder(x1)\n",
    "            mu2, sigma_square2 = self.encoder(x2)\n",
    "\n",
    "        # TODO: Linearly interpolate between these mean vectors (Use the function interpolate_mu)\n",
    "            for j in range(11):\n",
    "                z_a[j] = self.interpolate_mu(mu1, mu2, 0.1*j)\n",
    "\n",
    "        # TODO: Along the interpolation, plot the distributions p(x|z_α)\n",
    "            ps = self.decoder(z_a)\n",
    "            img[i] = torch.tensor([array_to_image(p.detach()) for p in ps])\n",
    "        # Concatenate these plots into one figure\n",
    "        img = img.view(-1, 28, 28)\n",
    "        result = concat_images(img, 11, 3)\n",
    "        plt.imshow(result, 'gray')\n",
    "        plt.savefig('interpolate.png')\n",
    "        plt.show()\n",
    "      \n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=globals()['__doc__'])\n",
    "\n",
    "    parser.add_argument('--e_path', type=str, default=\"./e_params.pkl\", help='Path to the encoder parameters.')\n",
    "    parser.add_argument('--d_path', type=str, default=\"./d_params.pkl\", help='Path to the decoder parameters.')\n",
    "    parser.add_argument('--hidden_units', type=int, default=500, help='Number of hidden units of the encoder and decoder models.')\n",
    "    parser.add_argument('--latent_dimension', type=int, default='2', help='Dimensionality of the latent space.')\n",
    "    parser.add_argument('--data_dimension', type=int, default='784', help='Dimensionality of the data space.')\n",
    "    parser.add_argument('--resume_training', action='store_true', help='Whether to resume training')\n",
    "    parser.add_argument('--seed', type=int, default=1234, help='Random seed')\n",
    "    parser.add_argument('--num_epoches', type=int, default=200, help='Number of epochs for training.')\n",
    "    parser.add_argument('--batch_size', type=int, default=100, help='Batch size.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # read the function arguments\n",
    "    #args = parse_args()\n",
    "\n",
    "    # set the random seed \n",
    "    seed = 1234\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "    \n",
    "    # train the model \n",
    "    vae = VAE()\n",
    "    vae.train()\n",
    "\n",
    "    # visualize the latent space\n",
    "    vae.visualize_data_space()\n",
    "    vae.visualize_latent_space()\n",
    "    vae.visualize_inter_class_interpolation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 0, ELBO:-548.4129028320312\n",
      "Epoch: 1, Iter: 100, ELBO:-362.7442626953125\n",
      "Epoch: 2, Iter: 200, ELBO:-744.4083862304688\n",
      "Epoch: 3, Iter: 300, ELBO:-2645.555419921875\n",
      "Epoch: 4, Iter: 400, ELBO:-26927.068359375\n",
      "Epoch: 5, Iter: 500, ELBO:-311977.75\n",
      "Epoch: 6, Iter: 600, ELBO:-445192.8125\n",
      "Epoch: 7, Iter: 700, ELBO:-2647.596923828125\n",
      "Epoch: 8, Iter: 800, ELBO:-507.5845642089844\n",
      "Epoch: 9, Iter: 900, ELBO:-509.9598693847656\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected p_in >= 0 && p_in <= 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-a55d126ad5d8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# visualize the latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_data_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_latent_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_inter_class_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-a55d126ad5d8>\u001b[0m in \u001b[0;36mvisualize_data_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# TODO: Sample x from p(x|z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_Bernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mimages_x\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marray_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-a55d126ad5d8>\u001b[0m in \u001b[0;36msample_Bernoulli\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# TODO: Implement a sampler from a Bernoulli distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected p_in >= 0 && p_in <= 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
