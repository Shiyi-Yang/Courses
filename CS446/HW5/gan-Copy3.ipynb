{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/234 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done. Total 60000 data entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/234 [00:00<01:00,  3.87it/s]\u001b[A\n",
      "  1%|          | 2/234 [00:00<00:41,  5.57it/s]\u001b[A\n",
      "  1%|▏         | 3/234 [00:00<00:38,  6.08it/s]\u001b[A\n",
      "  2%|▏         | 4/234 [00:00<00:33,  6.86it/s]\u001b[A\n",
      "  2%|▏         | 5/234 [00:00<00:33,  6.90it/s]\u001b[A\n",
      "  3%|▎         | 6/234 [00:00<00:33,  6.90it/s]\u001b[A\n",
      "  3%|▎         | 7/234 [00:01<00:32,  6.88it/s]\u001b[A\n",
      "  3%|▎         | 8/234 [00:01<00:32,  6.97it/s]\u001b[A\n",
      "  4%|▍         | 9/234 [00:01<00:31,  7.18it/s]\u001b[A\n",
      "  4%|▍         | 10/234 [00:01<00:30,  7.37it/s]\u001b[A\n",
      "  5%|▍         | 11/234 [00:01<00:30,  7.21it/s]\u001b[A\n",
      "  5%|▌         | 12/234 [00:01<00:32,  6.93it/s]\u001b[A\n",
      "  6%|▌         | 13/234 [00:01<00:31,  7.01it/s]\u001b[A\n",
      "  6%|▌         | 14/234 [00:02<00:31,  7.01it/s]\u001b[A\n",
      "  6%|▋         | 15/234 [00:02<00:29,  7.41it/s]\u001b[A\n",
      "  7%|▋         | 16/234 [00:02<00:29,  7.49it/s]\u001b[A\n",
      "  7%|▋         | 17/234 [00:02<00:28,  7.61it/s]\u001b[A\n",
      "  8%|▊         | 18/234 [00:02<00:27,  7.86it/s]\u001b[A\n",
      "  8%|▊         | 19/234 [00:02<00:27,  7.84it/s]\u001b[A\n",
      "  9%|▊         | 20/234 [00:02<00:28,  7.42it/s]\u001b[A\n",
      "  9%|▉         | 21/234 [00:02<00:29,  7.19it/s]\u001b[A\n",
      "  9%|▉         | 22/234 [00:03<00:30,  6.98it/s]\u001b[A\n",
      " 10%|▉         | 23/234 [00:03<00:29,  7.14it/s]\u001b[A\n",
      " 10%|█         | 24/234 [00:03<00:29,  7.09it/s]\u001b[A\n",
      " 11%|█         | 25/234 [00:03<00:29,  7.07it/s]\u001b[A\n",
      " 11%|█         | 26/234 [00:03<00:28,  7.28it/s]\u001b[A\n",
      " 12%|█▏        | 27/234 [00:03<00:28,  7.29it/s]\u001b[A\n",
      " 12%|█▏        | 28/234 [00:03<00:29,  7.05it/s]\u001b[A\n",
      " 12%|█▏        | 29/234 [00:04<00:29,  6.86it/s]\u001b[A\n",
      " 13%|█▎        | 30/234 [00:04<00:30,  6.70it/s]\u001b[A\n",
      " 13%|█▎        | 31/234 [00:04<00:29,  6.86it/s]\u001b[A\n",
      " 14%|█▎        | 32/234 [00:04<00:29,  6.93it/s]\u001b[A\n",
      " 14%|█▍        | 33/234 [00:04<00:27,  7.30it/s]\u001b[A\n",
      " 15%|█▍        | 34/234 [00:04<00:26,  7.44it/s]\u001b[A\n",
      " 15%|█▍        | 35/234 [00:04<00:27,  7.20it/s]\u001b[A\n",
      " 15%|█▌        | 36/234 [00:05<00:28,  6.99it/s]\u001b[A\n",
      " 16%|█▌        | 37/234 [00:05<00:27,  7.21it/s]\u001b[A\n",
      " 16%|█▌        | 38/234 [00:05<00:26,  7.50it/s]\u001b[A\n",
      " 17%|█▋        | 39/234 [00:05<00:27,  7.07it/s]\u001b[A\n",
      " 17%|█▋        | 40/234 [00:05<00:25,  7.47it/s]\u001b[A\n",
      " 18%|█▊        | 41/234 [00:05<00:25,  7.52it/s]\u001b[A\n",
      " 18%|█▊        | 42/234 [00:05<00:26,  7.28it/s]\u001b[A\n",
      " 18%|█▊        | 43/234 [00:06<00:26,  7.10it/s]\u001b[A\n",
      " 19%|█▉        | 44/234 [00:06<00:27,  6.87it/s]\u001b[A\n",
      " 19%|█▉        | 45/234 [00:06<00:26,  7.25it/s]\u001b[A\n",
      " 20%|█▉        | 46/234 [00:06<00:26,  7.03it/s]\u001b[A\n",
      " 20%|██        | 47/234 [00:06<00:26,  7.06it/s]\u001b[A\n",
      " 21%|██        | 48/234 [00:06<00:26,  6.91it/s]\u001b[A\n",
      " 21%|██        | 49/234 [00:06<00:26,  6.92it/s]\u001b[A\n",
      " 21%|██▏       | 50/234 [00:07<00:26,  7.07it/s]\u001b[A\n",
      " 22%|██▏       | 51/234 [00:07<00:24,  7.56it/s]\u001b[A\n",
      " 22%|██▏       | 52/234 [00:07<00:24,  7.32it/s]\u001b[A\n",
      " 23%|██▎       | 53/234 [00:07<00:24,  7.43it/s]\u001b[A\n",
      " 23%|██▎       | 54/234 [00:07<00:25,  6.95it/s]\u001b[A\n",
      " 24%|██▎       | 55/234 [00:07<00:25,  7.09it/s]\u001b[A\n",
      " 24%|██▍       | 56/234 [00:07<00:26,  6.69it/s]\u001b[A\n",
      " 24%|██▍       | 57/234 [00:08<00:24,  7.17it/s]\u001b[A\n",
      " 25%|██▍       | 58/234 [00:08<00:24,  7.12it/s]\u001b[A\n",
      " 25%|██▌       | 59/234 [00:08<00:25,  6.80it/s]\u001b[A\n",
      " 26%|██▌       | 60/234 [00:08<00:25,  6.95it/s]\u001b[A\n",
      " 26%|██▌       | 61/234 [00:08<00:24,  7.14it/s]\u001b[A\n",
      " 26%|██▋       | 62/234 [00:08<00:23,  7.41it/s]\u001b[A\n",
      " 27%|██▋       | 63/234 [00:08<00:23,  7.41it/s]\u001b[A\n",
      " 27%|██▋       | 64/234 [00:09<00:24,  7.07it/s]\u001b[A\n",
      " 28%|██▊       | 65/234 [00:09<00:23,  7.06it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-a71d09815746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-158-a71d09815746>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iter_d, iter_g, n_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mdopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                     \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loss_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m                     \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mdopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-158-a71d09815746>\u001b[0m in \u001b[0;36m_get_loss_d\u001b[0;34m(self, batch_size, batch_data, z)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mloss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-158-a71d09815746>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mz_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import struct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from hw5_utils import BASE_URL, download, GANDataset\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        \n",
    "        # TODO: implement layers here\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,2,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(2,4,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(4,8,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5*5*8,1),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        for child in self.model.children():\n",
    "            if type(child) == (nn.Conv2d) or type(child)==nn.Linear:\n",
    "                nn.init.kaiming_uniform_(child.weight)\n",
    "                nn.init.zeros_(child.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: complete forward function\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNet(nn.Module):\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "        # TODO: implement layers here\n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Linear(zdim,1568),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        self.model2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32,16,3,padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(16,8,3,padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(8,1,3,padding=1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        for child in self.model1.children():\n",
    "            if type(child) == (nn.Conv2d) or type(child)==nn.Linear:\n",
    "                nn.init.kaiming_uniform_(child.weight)\n",
    "                nn.init.zeros_(child.bias)\n",
    "        for child in self.model2.children():\n",
    "            if type(child) == (nn.Conv2d) or type(child)==nn.Linear:\n",
    "                nn.init.kaiming_uniform_(child.weight)\n",
    "                nn.init.zeros_(child.bias)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            z: latent variables used to generate images.\n",
    "        \"\"\"\n",
    "        # TODO: complete forward function\n",
    "        z_temp = self.model1(z)\n",
    "        z = z_temp.view(-1,32,7,7)\n",
    "        z = self.model2(z)\n",
    "        return z\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, zdim=64):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(2)\n",
    "        self._dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self._zdim = zdim\n",
    "        self.disc = DNet().to(self._dev)\n",
    "        self.gen = GNet(self._zdim).to(self._dev)\n",
    "\n",
    "    def _get_loss_d(self, batch_size, batch_data, z):\n",
    "        \"\"\"This function computes loss for discriminator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size: #data per batch.\n",
    "            batch_data: data from dataset.\n",
    "            z: random latent variable.\n",
    "        \"\"\"\n",
    "        # TODO: implement discriminator's loss function\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss_real = criterion(self.disc(batch_data),torch.ones(batch_size,1))\n",
    "        loss_fake = criterion(self.disc(self.gen(z)),torch.zeros(batch_size,1))\n",
    "        \n",
    "        loss_d = (loss_real + loss_fake)/2\n",
    "        return loss_d\n",
    "\n",
    "    def _get_loss_g(self, batch_size, z):\n",
    "        \"\"\"This function computes loss for generator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size: #data per batch.\n",
    "            z: random latent variable.\n",
    "        \"\"\"\n",
    "        # TODO: implement generator's loss function\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss_g = criterion(self.disc(self.gen(z)),torch.ones(batch_size,1))\n",
    "        return loss_g\n",
    "\n",
    "    def train(self, iter_d=1, iter_g=1, n_epochs=100, batch_size=256, lr=0.0002):\n",
    "\n",
    "        # first download\n",
    "        f_name = \"train-images-idx3-ubyte.gz\"\n",
    "        download(BASE_URL + f_name, f_name)\n",
    "\n",
    "        print(\"Processing dataset ...\")\n",
    "        train_data = GANDataset(\n",
    "            f\"./data/{f_name}\",\n",
    "            self._dev,\n",
    "            transform=transforms.Compose([transforms.Normalize((0.0,), (255.0,))]),\n",
    "        )\n",
    "        print(f\"... done. Total {len(train_data)} data entries.\")\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "        dopt = optim.Adam(self.disc.parameters(), lr=lr, weight_decay=0.0)\n",
    "        dopt.zero_grad()\n",
    "        gopt = optim.Adam(self.gen.parameters(), lr=lr, weight_decay=0.0)\n",
    "        gopt.zero_grad()\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "            for batch_idx, data in tqdm(\n",
    "                enumerate(train_loader), total=len(train_loader)\n",
    "            ):\n",
    "\n",
    "                z = 2 * torch.rand(data.size()[0], self._zdim, device=self._dev) - 1\n",
    "\n",
    "                if batch_idx == 0 and epoch == 0:\n",
    "                    plt.imshow(data[0, 0, :, :].detach().cpu().numpy())\n",
    "                    plt.savefig(\"goal.pdf\")\n",
    "\n",
    "                if batch_idx == 0 and epoch % 10 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        tmpimg = self.gen(z)[0:64, :, :, :].detach().cpu()\n",
    "                    save_image(\n",
    "                        tmpimg, \"test_{0}.png\".format(epoch), nrow=8, normalize=True\n",
    "                    )\n",
    "\n",
    "                dopt.zero_grad()\n",
    "                for k in range(iter_d):\n",
    "                    loss_d = self._get_loss_d(batch_size, data, z)\n",
    "                    loss_d.backward()\n",
    "                    dopt.step()\n",
    "                    dopt.zero_grad()\n",
    "\n",
    "                gopt.zero_grad()\n",
    "                for k in range(iter_g):\n",
    "                    loss_g = self._get_loss_g(batch_size, z)\n",
    "                    loss_g.backward()\n",
    "                    gopt.step()\n",
    "                    gopt.zero_grad()\n",
    "\n",
    "            print(f\"E: {epoch}; DLoss: {loss_d.item()}; GLoss: {loss_g.item()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gan = GAN()\n",
    "    gan.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNet(nn.Module):\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        \n",
    "        # TODO: implement layers here\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1,2,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(2,4,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(4,8,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5*5*8,1),\n",
    "        )\n",
    "        \n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        for child in self.model.children():\n",
    "            #print(child.parameters())\n",
    "            #print(child.__class__.__name__)\n",
    "            #print(type(child))\n",
    "            if type(child) == (nn.Conv2d) or type(child)==nn.Linear:\n",
    "                print(child)\n",
    "                nn.init.kaiming_uniform_(child.weight)\n",
    "                nn.init.zeros_(child.bias)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # TODO: complete forward function\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "Linear(in_features=200, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "net = DNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=200, out_features=1, bias=True)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.model[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(256,3,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 18])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/234 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done. Total 60000 data entries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/234 [00:00<01:02,  3.70it/s]\u001b[A\n",
      "  1%|          | 2/234 [00:00<00:41,  5.63it/s]\u001b[A\n",
      "  2%|▏         | 4/234 [00:00<00:27,  8.36it/s]\u001b[A\n",
      "  2%|▏         | 5/234 [00:00<00:26,  8.80it/s]\u001b[A\n",
      "  3%|▎         | 7/234 [00:00<00:23,  9.49it/s]\u001b[A\n",
      "  3%|▎         | 8/234 [00:00<00:26,  8.62it/s]\u001b[A\n",
      "  4%|▍         | 9/234 [00:01<00:25,  8.90it/s]\u001b[A\n",
      "  4%|▍         | 10/234 [00:01<00:26,  8.41it/s]\u001b[A\n",
      "  5%|▍         | 11/234 [00:01<00:26,  8.36it/s]\u001b[A\n",
      "  5%|▌         | 12/234 [00:01<00:27,  8.17it/s]\u001b[A\n",
      "  6%|▌         | 13/234 [00:01<00:28,  7.84it/s]\u001b[A\n",
      "  6%|▌         | 14/234 [00:01<00:27,  8.08it/s]\u001b[A\n",
      "  6%|▋         | 15/234 [00:01<00:26,  8.16it/s]\u001b[A\n",
      "  7%|▋         | 16/234 [00:01<00:27,  8.06it/s]\u001b[A\n",
      "  7%|▋         | 17/234 [00:02<00:26,  8.17it/s]\u001b[A\n",
      "  8%|▊         | 19/234 [00:02<00:23,  9.11it/s]\u001b[A\n",
      "  9%|▊         | 20/234 [00:02<00:23,  9.08it/s]\u001b[A\n",
      "  9%|▉         | 21/234 [00:02<00:23,  9.02it/s]\u001b[A\n",
      "  9%|▉         | 22/234 [00:02<00:24,  8.81it/s]\u001b[A\n",
      " 10%|█         | 24/234 [00:02<00:21,  9.58it/s]\u001b[A\n",
      " 11%|█         | 25/234 [00:02<00:22,  9.44it/s]\u001b[A\n",
      " 11%|█         | 26/234 [00:03<00:24,  8.34it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-03d1b5d31f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-03d1b5d31f28>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iter_d, iter_g, n_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loss_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                     \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0mdopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "\n",
    "from hw5_utils import BASE_URL, download, GANDataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DNet(nn.Module):\n",
    "\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DNet, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=0, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8*5*5, 1, bias=True)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GNet(nn.Module):\n",
    "\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            zdim: dimension for latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "\n",
    "            nn.Linear(zdim, 1568, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.f2 = nn.Sequential(\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f1.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "        for child in list(self.f2.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            z: latent variables used to generate images.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        hidden = self.f1(z)\n",
    "\n",
    "        return self.f2(hidden.view(-1, 32, 7, 7))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GAN:\n",
    "\n",
    "    def __init__(self, zdim=64):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            zdim: dimension for latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(2)\n",
    "\n",
    "        self._dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "        self._zdim = zdim\n",
    "\n",
    "        self.disc = DNet().to(self._dev)\n",
    "\n",
    "        self.gen = GNet(self._zdim).to(self._dev)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_loss_d(self, batch_size, batch_data, z):\n",
    "\n",
    "        \"\"\"This function computes loss for discriminator.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            batch_size: #data per batch.\n",
    "\n",
    "            batch_data: data from dataset.\n",
    "\n",
    "            z: random latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement discriminator's loss function\n",
    "\n",
    "        # pos_weight = torch.ones([batch_size])\n",
    "\n",
    "\n",
    "\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "        loss_real = criterion(self.disc(batch_data), torch.ones((batch_size, 1), device=self._dev))\n",
    "\n",
    "        loss_fake = criterion(self.disc(self.gen(z)), torch.zeros((batch_size, 1), device=self._dev))\n",
    "\n",
    "\n",
    "\n",
    "        loss_d = (loss_real + loss_fake) / 2\n",
    "\n",
    "        return loss_d\n",
    "\n",
    "\n",
    "\n",
    "    def _get_loss_g(self, batch_size, z):\n",
    "\n",
    "        \"\"\"This function computes loss for generator.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            batch_size: #data per batch.\n",
    "\n",
    "            z: random latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement generator's loss function\n",
    "\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "        loss_g = criterion(self.disc(self.gen(z)), torch.ones((batch_size, 1), device=self._dev))\n",
    "\n",
    "        return loss_g\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, iter_d=1, iter_g=1, n_epochs=100, batch_size=256, lr=0.0002):\n",
    "\n",
    "\n",
    "\n",
    "        # first download\n",
    "\n",
    "        f_name = \"train-images-idx3-ubyte.gz\"\n",
    "\n",
    "        download(BASE_URL + f_name, f_name)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Processing dataset ...\")\n",
    "\n",
    "        train_data = GANDataset(\n",
    "\n",
    "            f\"./data/{f_name}\",\n",
    "\n",
    "            self._dev,\n",
    "\n",
    "            transform=transforms.Compose([transforms.Normalize((0.0,), (255.0,))]),\n",
    "\n",
    "        )\n",
    "\n",
    "        print(f\"... done. Total {len(train_data)} data entries.\")\n",
    "\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "\n",
    "            train_data,\n",
    "\n",
    "            batch_size=batch_size,\n",
    "\n",
    "            shuffle=True,\n",
    "\n",
    "            num_workers=0,\n",
    "\n",
    "            drop_last=True,\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        dopt = optim.Adam(self.disc.parameters(), lr=lr, weight_decay=0.0)\n",
    "\n",
    "        dopt.zero_grad()\n",
    "\n",
    "        gopt = optim.Adam(self.gen.parameters(), lr=lr, weight_decay=0.0)\n",
    "\n",
    "        gopt.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "            for batch_idx, data in tqdm(\n",
    "\n",
    "                enumerate(train_loader), total=len(train_loader)\n",
    "\n",
    "            ):\n",
    "\n",
    "\n",
    "\n",
    "                z = 2 * torch.rand(data.size()[0], self._zdim, device=self._dev) - 1\n",
    "\n",
    "\n",
    "\n",
    "                if batch_idx == 0 and epoch == 0:\n",
    "\n",
    "                    plt.imshow(data[0, 0, :, :].detach().cpu().numpy())\n",
    "\n",
    "                    plt.savefig(\"goal.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "                if batch_idx == 0 and epoch % 10 == 0:\n",
    "\n",
    "                    with torch.no_grad():\n",
    "\n",
    "                        tmpimg = self.gen(z)[0:64, :, :, :].detach().cpu()\n",
    "\n",
    "                    save_image(\n",
    "\n",
    "                        tmpimg, \"test_{0}.png\".format(epoch), nrow=8, normalize=True\n",
    "\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "                dopt.zero_grad()\n",
    "\n",
    "                for k in range(iter_d):\n",
    "\n",
    "                    loss_d = self._get_loss_d(batch_size, data, z)\n",
    "\n",
    "                    loss_d.backward()\n",
    "\n",
    "                    dopt.step()\n",
    "\n",
    "                    dopt.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "                gopt.zero_grad()\n",
    "\n",
    "                for k in range(iter_g):\n",
    "\n",
    "                    loss_g = self._get_loss_g(batch_size, z)\n",
    "\n",
    "                    loss_g.backward()\n",
    "\n",
    "                    gopt.step()\n",
    "\n",
    "                    gopt.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"E: {epoch}; DLoss: {loss_d.item()}; GLoss: {loss_g.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    gan = GAN()\n",
    "\n",
    "    gan.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11,  4,  2,  1,  2,  3,  2,  5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNet(nn.Module):\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            zdim: dimension for latent variable.\n",
    "        \"\"\"\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "        # TODO: implement layers here\n",
    "        self.fc1 = nn.Linear(zdim,1568)\n",
    "        #Relu\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        self.upsample1 = nn.Upsample(scale_factor =2)\n",
    "        self.conv1 = nn.Conv2d(32,16,3,padding=1)\n",
    "        ##Relu\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        self.upsample2 = nn.Upsample(scale_factor = 2)\n",
    "        self.conv2 = nn.Conv2d(16,8,3,padding = 1)\n",
    "        self.relu3 = nn.LeakyReLU(0.2)\n",
    "        self.conv3 = nn.Conv2d(8,1,3,padding = 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self._weight_init()\n",
    "\n",
    "    def _weight_init(self):\n",
    "        # TODO: implement weight initialization here\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight)\n",
    "        nn.init.kaiming_uniform_(self.conv3.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.zeros_(self.conv2.bias)\n",
    "        nn.init.zeros_(self.conv3.bias)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            z: latent variables used to generate images.\n",
    "        \"\"\"\n",
    "        # TODO: complete forward function\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        #z = F.leaky_relu(z,0.2)\n",
    "        z = z.view(-1,32,7,7)\n",
    "        z = self.upsample1(z)\n",
    "        #z = F.leaky_relu(self.conv1(z),0.2)\n",
    "        z = self.conv1(z)\n",
    "        z = self.relu2(z)\n",
    "        #z = self.relu2(self.conv1(z),0.2)\n",
    "        z = self.upsample2(z)\n",
    "        #z = F.leaky_relu(self.conv2(z),0.2)\n",
    "        z = self.conv2(z)\n",
    "        z = self.relu3(z)\n",
    "        z = self.conv3(z)\n",
    "        z = self.sigmoid(z)\n",
    "        #z = F.sigmoid(self.conv3(z))\n",
    "        #z = self.sigmoid(self.conv3(z))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNet(\n",
       "  (fc1): Linear(in_features=10, out_features=1568, bias=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.2)\n",
       "  (upsample1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2): LeakyReLU(negative_slope=0.2)\n",
       "  (upsample2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3): LeakyReLU(negative_slope=0.2)\n",
       "  (conv3): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = GNet(10)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 3, 3])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.conv1.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=1568, bias=True) Parameter containing:\n",
      "tensor([[ 0.2704, -0.4921,  0.3480,  ..., -0.1466, -0.5017,  0.7449],\n",
      "        [ 0.1114,  0.5307,  0.1091,  ..., -0.0559, -0.3466,  0.4842],\n",
      "        [-0.3158,  0.1466,  0.0827,  ..., -0.0497,  0.1972, -0.0890],\n",
      "        ...,\n",
      "        [ 0.2438, -0.4411,  0.7375,  ...,  0.6158,  0.6671,  0.3513],\n",
      "        [-0.4990,  0.4153,  0.5074,  ..., -0.6468, -0.4194,  0.0128],\n",
      "        [ 0.1034, -0.2834,  0.6123,  ..., -0.6237, -0.7643, -0.1279]],\n",
      "       requires_grad=True)\n",
      "Linear(in_features=10, out_features=1568, bias=True) Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 3, 3])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2 = GNet2(10)\n",
    "g2\n",
    "g2.f2[1].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 28, 28])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,1,28,28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4360],\n",
       "        [0.7328],\n",
       "        [0.5797],\n",
       "        [0.0066],\n",
       "        [0.4851]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = g.forward(x)\n",
    "t1.size()\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2797],\n",
       "        [ 4.0545],\n",
       "        [-0.0111],\n",
       "        [ 5.7228],\n",
       "        [ 2.4843]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = g2.forward(x)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNet2(nn.Module):\n",
    "\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            zdim: dimension for latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(GNet2, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "\n",
    "            nn.Linear(zdim, 1568, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.f2 = nn.Sequential(\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f1.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "                print(child,child.weight)\n",
    "                print(child,child.bias)\n",
    "\n",
    "        for child in list(self.f2.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            z: latent variables used to generate images.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        hidden = self.f1(z)\n",
    "\n",
    "        return self.f2(hidden.view(-1, 32, 7, 7))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNet2(nn.Module):\n",
    "\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DNet2, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=0, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(8*5*5, 1, bias=True)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        return self.f(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
