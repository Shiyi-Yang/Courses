{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/234 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done. Total 60000 data entries.\n",
      "torch.Size([256, 200])\n",
      "torch.Size([256, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/234 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([256, 1])) must be the same as input size (torch.Size([256, 200]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e6562cf43ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e6562cf43ac1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iter_d, iter_g, n_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loss_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                     \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e6562cf43ac1>\u001b[0m in \u001b[0;36m_get_loss_d\u001b[0;34m(self, batch_size, batch_data, z)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mloss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    630\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pythonenvs/py3.8/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2580\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([256, 1])) must be the same as input size (torch.Size([256, 200]))"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "\n",
    "from hw5_utils import BASE_URL, download, GANDataset\n",
    "\n",
    "\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n",
    "class DNet(nn.Module):\n",
    "\n",
    "    \"\"\"This is discriminator network.\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(DNet, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(4, 8, kernel_size=3, stride=1, padding=0, bias=True),\n",
    "\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            PrintLayer(),\n",
    "\n",
    "            #nn.Linear(8*5*5, 1, bias=True)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO: complete forward function\n",
    "        f = self.f(x)\n",
    "        \n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GNet(nn.Module):\n",
    "\n",
    "    \"\"\"This is generator network.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, zdim):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            zdim: dimension for latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(GNet, self).__init__()\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: implement layers here\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "\n",
    "            nn.Linear(zdim, 1568, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.f2 = nn.Sequential(\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        self._weight_init()\n",
    "\n",
    "\n",
    "\n",
    "    def _weight_init(self):\n",
    "\n",
    "        # TODO: implement weight initialization here\n",
    "\n",
    "        for child in list(self.f1.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "        for child in list(self.f2.children()):\n",
    "\n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "\n",
    "                nn.init.kaiming_uniform_(child.weight.data)\n",
    "\n",
    "                nn.init.zeros_(child.bias.data)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            z: latent variables used to generate images.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: complete forward function\n",
    "\n",
    "        hidden = self.f1(z)\n",
    "\n",
    "        return self.f2(hidden.view(-1, 32, 7, 7))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GAN:\n",
    "\n",
    "    def __init__(self, zdim=64):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            zdim: dimension for latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(2)\n",
    "\n",
    "        self._dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "        self._zdim = zdim\n",
    "\n",
    "        self.disc = DNet().to(self._dev)\n",
    "\n",
    "        self.gen = GNet(self._zdim).to(self._dev)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_loss_d(self, batch_size, batch_data, z):\n",
    "\n",
    "        \"\"\"This function computes loss for discriminator.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            batch_size: #data per batch.\n",
    "\n",
    "            batch_data: data from dataset.\n",
    "\n",
    "            z: random latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement discriminator's loss function\n",
    "\n",
    "        # pos_weight = torch.ones([batch_size])\n",
    "\n",
    "\n",
    "\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "        loss_real = criterion(self.disc(batch_data), torch.ones((batch_size, 1), device=self._dev))\n",
    "\n",
    "        loss_fake = criterion(self.disc(self.gen(z)), torch.zeros((batch_size, 1), device=self._dev))\n",
    "\n",
    "\n",
    "\n",
    "        loss_d = (loss_real + loss_fake) / 2\n",
    "\n",
    "        return loss_d\n",
    "\n",
    "\n",
    "\n",
    "    def _get_loss_g(self, batch_size, z):\n",
    "\n",
    "        \"\"\"This function computes loss for generator.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "            batch_size: #data per batch.\n",
    "\n",
    "            z: random latent variable.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: implement generator's loss function\n",
    "\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "        loss_g = criterion(self.disc(self.gen(z)), torch.ones((batch_size, 1), device=self._dev))\n",
    "\n",
    "        return loss_g\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, iter_d=1, iter_g=1, n_epochs=100, batch_size=256, lr=0.0002):\n",
    "\n",
    "\n",
    "\n",
    "        # first download\n",
    "\n",
    "        f_name = \"train-images-idx3-ubyte.gz\"\n",
    "\n",
    "        download(BASE_URL + f_name, f_name)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Processing dataset ...\")\n",
    "\n",
    "        train_data = GANDataset(\n",
    "\n",
    "            f\"./data/{f_name}\",\n",
    "\n",
    "            self._dev,\n",
    "\n",
    "            transform=transforms.Compose([transforms.Normalize((0.0,), (255.0,))]),\n",
    "\n",
    "        )\n",
    "\n",
    "        print(f\"... done. Total {len(train_data)} data entries.\")\n",
    "\n",
    "\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "\n",
    "            train_data,\n",
    "\n",
    "            batch_size=batch_size,\n",
    "\n",
    "            shuffle=True,\n",
    "\n",
    "            num_workers=0,\n",
    "\n",
    "            drop_last=True,\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        dopt = optim.Adam(self.disc.parameters(), lr=lr, weight_decay=0.0)\n",
    "\n",
    "        dopt.zero_grad()\n",
    "\n",
    "        gopt = optim.Adam(self.gen.parameters(), lr=lr, weight_decay=0.0)\n",
    "\n",
    "        gopt.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "            for batch_idx, data in tqdm(\n",
    "\n",
    "                enumerate(train_loader), total=len(train_loader)\n",
    "\n",
    "            ):\n",
    "\n",
    "\n",
    "\n",
    "                z = 2 * torch.rand(data.size()[0], self._zdim, device=self._dev) - 1\n",
    "\n",
    "\n",
    "\n",
    "                if batch_idx == 0 and epoch == 0:\n",
    "\n",
    "                    plt.imshow(data[0, 0, :, :].detach().cpu().numpy())\n",
    "\n",
    "                    plt.savefig(\"goal.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "                if batch_idx == 0 and epoch % 10 == 0:\n",
    "\n",
    "                    with torch.no_grad():\n",
    "\n",
    "                        tmpimg = self.gen(z)[0:64, :, :, :].detach().cpu()\n",
    "\n",
    "                    save_image(\n",
    "\n",
    "                        tmpimg, \"test_{0}.png\".format(epoch), nrow=8, normalize=True\n",
    "\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "                dopt.zero_grad()\n",
    "\n",
    "                for k in range(iter_d):\n",
    "\n",
    "                    loss_d = self._get_loss_d(batch_size, data, z)\n",
    "\n",
    "                    loss_d.backward()\n",
    "\n",
    "                    dopt.step()\n",
    "\n",
    "                    dopt.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "                gopt.zero_grad()\n",
    "\n",
    "                for k in range(iter_g):\n",
    "\n",
    "                    loss_g = self._get_loss_g(batch_size, z)\n",
    "\n",
    "                    loss_g.backward()\n",
    "\n",
    "                    gopt.step()\n",
    "\n",
    "                    gopt.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"E: {epoch}; DLoss: {loss_d.item()}; GLoss: {loss_g.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    gan = GAN()\n",
    "\n",
    "    gan.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
